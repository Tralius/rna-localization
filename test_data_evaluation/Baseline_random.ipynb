{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from metrics import Pearson\n",
    "from utils import prepare_data\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dataloaders import GeneDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/Users/jonasflor/Downloads/Baseline_random.h5',\n",
    "                   custom_objects={'Pearson': Pearson})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "dataloader = GeneDataLoader(test_data, padding_length=train_data['seq'].apply(lambda x: len(x)).max(), shuffle=False, struct=False)\n",
    "\n",
    "prediction = []\n",
    "y_test = []\n",
    "\n",
    "for i, j in dataloader:\n",
    "    prediction.append(model.predict(i[0]))\n",
    "    y_test.append(j)\n",
    "\n",
    "prediction = np.concatenate(prediction)\n",
    "y_test = np.concatenate(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_dict(y_true, y_pred):\n",
    "    y_true_std = tfp.stats.stddev(y_true, sample_axis=0, keepdims=True)\n",
    "    y_pred_std = tfp.stats.stddev(y_pred, sample_axis=0, keepdims=True)\n",
    "    \n",
    "    y_true /= (y_true_std + 1e-3)\n",
    "    y_pred /= (y_pred_std + 1e-3)\n",
    "    \n",
    "    result = tfp.stats.covariance(x=y_true,\n",
    "                                y=y_pred,\n",
    "                                event_axis=None,\n",
    "                                sample_axis=0,\n",
    "                                keepdims=False)\n",
    "    res_dict = {}\n",
    "    res_dict['ERM'] = result[0]\n",
    "    res_dict['KDEL'] = result[1]\n",
    "    res_dict['LMA'] = result[2]\n",
    "    res_dict['MITO'] = result[3]\n",
    "    res_dict['NES'] = result[4]\n",
    "    res_dict['NIK'] = result[5]\n",
    "    res_dict['NLS'] = result[6]\n",
    "    res_dict['NUCP'] = result[7]\n",
    "    res_dict['OMM'] = result[8]\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERM': <tf.Tensor: shape=(), dtype=float32, numpy=-0.1376238>,\n",
       " 'KDEL': <tf.Tensor: shape=(), dtype=float32, numpy=0.05013642>,\n",
       " 'LMA': <tf.Tensor: shape=(), dtype=float32, numpy=-0.0050322255>,\n",
       " 'MITO': <tf.Tensor: shape=(), dtype=float32, numpy=-0.014031444>,\n",
       " 'NES': <tf.Tensor: shape=(), dtype=float32, numpy=0.013364872>,\n",
       " 'NIK': <tf.Tensor: shape=(), dtype=float32, numpy=0.10040313>,\n",
       " 'NLS': <tf.Tensor: shape=(), dtype=float32, numpy=0.09802337>,\n",
       " 'NUCP': <tf.Tensor: shape=(), dtype=float32, numpy=0.116804175>,\n",
       " 'OMM': <tf.Tensor: shape=(), dtype=float32, numpy=0.08749543>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_dict(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna_localization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
