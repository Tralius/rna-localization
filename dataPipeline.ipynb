{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Genomics Project **RNA Localisation**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Problem definition**:\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.** First steps with data\n",
    "\n",
    "Firstly, we import several necessary packages and load in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "#from keras.utils import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "import tensorflow\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from GeneWrapper import Gene_Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a few parameters\n",
    "max_len = 4000\n",
    "nb_filters = 32\n",
    "filters_length = 10\n",
    "pooling_size = 3\n",
    "lstm_units = 32\n",
    "lower_bound = 0\n",
    "upper_bound = 4000\n",
    "nb_classes = 9 # because we have 9 localisations\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERM</th>\n",
       "      <th>KDEL</th>\n",
       "      <th>LMA</th>\n",
       "      <th>MITO</th>\n",
       "      <th>NES</th>\n",
       "      <th>NIK</th>\n",
       "      <th>NLS</th>\n",
       "      <th>NUCP</th>\n",
       "      <th>OMM</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207338</td>\n",
       "      <td>0.128871</td>\n",
       "      <td>0.079991</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.082833</td>\n",
       "      <td>0.088109</td>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.106670</td>\n",
       "      <td>0.199601</td>\n",
       "      <td>ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922605</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064346</td>\n",
       "      <td>0.125935</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>0.091019</td>\n",
       "      <td>0.160823</td>\n",
       "      <td>0.142649</td>\n",
       "      <td>0.131566</td>\n",
       "      <td>0.093474</td>\n",
       "      <td>TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141112</td>\n",
       "      <td>0.094932</td>\n",
       "      <td>0.211394</td>\n",
       "      <td>0.028049</td>\n",
       "      <td>0.102672</td>\n",
       "      <td>0.102581</td>\n",
       "      <td>0.124625</td>\n",
       "      <td>0.090767</td>\n",
       "      <td>0.103868</td>\n",
       "      <td>TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172315</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>0.132014</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.115743</td>\n",
       "      <td>0.088187</td>\n",
       "      <td>0.142063</td>\n",
       "      <td>0.105034</td>\n",
       "      <td>0.089878</td>\n",
       "      <td>AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13805</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734451</td>\n",
       "      <td>0.109981</td>\n",
       "      <td>0.073566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>0.067811</td>\n",
       "      <td>0.056029</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.050838</td>\n",
       "      <td>0.430809</td>\n",
       "      <td>0.110393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.059330</td>\n",
       "      <td>0.330415</td>\n",
       "      <td>0.263028</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>0.088620</td>\n",
       "      <td>ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077421</td>\n",
       "      <td>0.315861</td>\n",
       "      <td>0.053726</td>\n",
       "      <td>0.132350</td>\n",
       "      <td>0.051426</td>\n",
       "      <td>0.189963</td>\n",
       "      <td>0.110591</td>\n",
       "      <td>0.068661</td>\n",
       "      <td>CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>0.214586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022666</td>\n",
       "      <td>TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12429 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ERM      KDEL       LMA      MITO       NES       NIK       NLS  \\\n",
       "0      0.207338  0.128871  0.079991  0.044906  0.082833  0.088109  0.061681   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.064346  0.125935  0.108187  0.082002  0.091019  0.160823  0.142649   \n",
       "3      0.141112  0.094932  0.211394  0.028049  0.102672  0.102581  0.124625   \n",
       "4      0.172315  0.115240  0.132014  0.039526  0.115743  0.088187  0.142063   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13805  0.000000  0.000000  0.734451  0.109981  0.073566  0.000000  0.082002   \n",
       "13806  0.067811  0.056029  0.110082  0.010354  0.050838  0.430809  0.110393   \n",
       "13807  0.006797  0.081510  0.077941  0.046627  0.059330  0.330415  0.263028   \n",
       "13808  0.000000  0.077421  0.315861  0.053726  0.132350  0.051426  0.189963   \n",
       "13809  0.000000  0.307638  0.000000  0.044530  0.214586  0.000000  0.410580   \n",
       "\n",
       "           NUCP       OMM                                                seq  \n",
       "0      0.106670  0.199601  ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...  \n",
       "1      0.922605  0.077395  TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...  \n",
       "2      0.131566  0.093474  TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...  \n",
       "3      0.090767  0.103868  TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...  \n",
       "4      0.105034  0.089878  AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...  \n",
       "...         ...       ...                                                ...  \n",
       "13805  0.000000  0.000000  GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...  \n",
       "13806  0.000000  0.163685  GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...  \n",
       "13807  0.045733  0.088620  ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...  \n",
       "13808  0.110591  0.068661  CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...  \n",
       "13809  0.000000  0.022666  TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...  \n",
       "\n",
       "[12429 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing test set\n",
    "np.random.seed(3)\n",
    "data_org = pd.read_csv('~/Downloads/final_data.csv')\n",
    "test_data = data_org.sample(frac=0.1)\n",
    "train_data = data_org.drop(test_data.index) # TODO: note: we also have to preprocess the test set similary\n",
    "# TODO: colab\n",
    "\n",
    "\n",
    "data_org\n",
    "\n",
    "sum_vec = train_data.iloc[:, :9].sum(axis=1)\n",
    "data2 = train_data.iloc[:, :9].divide(sum_vec, axis='index')\n",
    "train_data_no_struct = pd.concat([data2, train_data['seq']], axis=1)\n",
    "train_data_no_struct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERM</th>\n",
       "      <th>KDEL</th>\n",
       "      <th>LMA</th>\n",
       "      <th>MITO</th>\n",
       "      <th>NES</th>\n",
       "      <th>NIK</th>\n",
       "      <th>NLS</th>\n",
       "      <th>NUCP</th>\n",
       "      <th>OMM</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207338</td>\n",
       "      <td>0.128871</td>\n",
       "      <td>0.079991</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.082833</td>\n",
       "      <td>0.088109</td>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.106670</td>\n",
       "      <td>0.199601</td>\n",
       "      <td>ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922605</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064346</td>\n",
       "      <td>0.125935</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>0.091019</td>\n",
       "      <td>0.160823</td>\n",
       "      <td>0.142649</td>\n",
       "      <td>0.131566</td>\n",
       "      <td>0.093474</td>\n",
       "      <td>TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141112</td>\n",
       "      <td>0.094932</td>\n",
       "      <td>0.211394</td>\n",
       "      <td>0.028049</td>\n",
       "      <td>0.102672</td>\n",
       "      <td>0.102581</td>\n",
       "      <td>0.124625</td>\n",
       "      <td>0.090767</td>\n",
       "      <td>0.103868</td>\n",
       "      <td>TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172315</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>0.132014</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.115743</td>\n",
       "      <td>0.088187</td>\n",
       "      <td>0.142063</td>\n",
       "      <td>0.105034</td>\n",
       "      <td>0.089878</td>\n",
       "      <td>AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13805</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734451</td>\n",
       "      <td>0.109981</td>\n",
       "      <td>0.073566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>0.067811</td>\n",
       "      <td>0.056029</td>\n",
       "      <td>0.110082</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.050838</td>\n",
       "      <td>0.430809</td>\n",
       "      <td>0.110393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.059330</td>\n",
       "      <td>0.330415</td>\n",
       "      <td>0.263028</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>0.088620</td>\n",
       "      <td>ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077421</td>\n",
       "      <td>0.315861</td>\n",
       "      <td>0.053726</td>\n",
       "      <td>0.132350</td>\n",
       "      <td>0.051426</td>\n",
       "      <td>0.189963</td>\n",
       "      <td>0.110591</td>\n",
       "      <td>0.068661</td>\n",
       "      <td>CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>0.214586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022666</td>\n",
       "      <td>TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12429 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ERM      KDEL       LMA      MITO       NES       NIK       NLS  \\\n",
       "0      0.207338  0.128871  0.079991  0.044906  0.082833  0.088109  0.061681   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.064346  0.125935  0.108187  0.082002  0.091019  0.160823  0.142649   \n",
       "3      0.141112  0.094932  0.211394  0.028049  0.102672  0.102581  0.124625   \n",
       "4      0.172315  0.115240  0.132014  0.039526  0.115743  0.088187  0.142063   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13805  0.000000  0.000000  0.734451  0.109981  0.073566  0.000000  0.082002   \n",
       "13806  0.067811  0.056029  0.110082  0.010354  0.050838  0.430809  0.110393   \n",
       "13807  0.006797  0.081510  0.077941  0.046627  0.059330  0.330415  0.263028   \n",
       "13808  0.000000  0.077421  0.315861  0.053726  0.132350  0.051426  0.189963   \n",
       "13809  0.000000  0.307638  0.000000  0.044530  0.214586  0.000000  0.410580   \n",
       "\n",
       "           NUCP       OMM                                                seq  \n",
       "0      0.106670  0.199601  ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...  \n",
       "1      0.922605  0.077395  TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...  \n",
       "2      0.131566  0.093474  TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...  \n",
       "3      0.090767  0.103868  TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...  \n",
       "4      0.105034  0.089878  AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...  \n",
       "...         ...       ...                                                ...  \n",
       "13805  0.000000  0.000000  GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...  \n",
       "13806  0.000000  0.163685  GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...  \n",
       "13807  0.045733  0.088620  ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...  \n",
       "13808  0.110591  0.068661  CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...  \n",
       "13809  0.000000  0.022666  TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...  \n",
       "\n",
       "[12429 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initializing test set\n",
    "np.random.seed(3)\n",
    "data_org = pd.read_csv('~/Downloads/final_data.csv')\n",
    "test_data = data_org.sample(frac=0.1)\n",
    "train_data = data_org.drop(test_data.index)  # TODO: note: we also have to preprocess the test set similary\n",
    "# TODO: colab\n",
    "\n",
    "\n",
    "data_org\n",
    "\n",
    "sum_vec = train_data.iloc[:, :9].sum(axis=1)\n",
    "data2 = train_data.iloc[:, :9].divide(sum_vec, axis='index')\n",
    "train_data_no_struct = pd.concat([data2, train_data['seq']], axis=1)\n",
    "train_data_no_struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One hot encode the 'seq' attribute of the above table\n",
    "mapping = {\n",
    "    'A': 0,\n",
    "    'C': 1,\n",
    "    'G': 2,\n",
    "    'T': 3\n",
    "}\n",
    "\n",
    "mapping_localisations = {\n",
    "    'ERM':  0,\n",
    "    'KDEL': 1,\n",
    "    'LMA':  2,\n",
    "    'MITO': 3,\n",
    "    'NES':  4,\n",
    "    'NIK':  5,\n",
    "    'NLS':  6,\n",
    "    'NUCP': 7,\n",
    "    'OMM':  8\n",
    "}\n",
    "\n",
    "one_hot_encode_lam = lambda seq: to_categorical([mapping[x] for x in seq])\n",
    "data_one = train_data_no_struct['seq'].apply(one_hot_encode_lam)\n",
    "\n",
    "data_one\n",
    "\n",
    "# Now just injecting this modified 'seq' back into the pandas frame\n",
    "data_one_no_struct =  pd.concat([train_data_no_struct.iloc[:, :9], data_one], axis=1)\n",
    "\n",
    "data_one_no_struct\n",
    "\n",
    "\n",
    "# Additional ordinal encoding of the 'seq' attribute\n",
    "\n",
    "gene_data = train_data['seq']\n",
    "\n",
    "def label_dist(dist):\n",
    "    # TODO: what is this\n",
    "    assert (len(dist) == 4)\n",
    "    return np.array(dist) / np.sum(dist)\n",
    "\n",
    "encoding_seq = OrderedDict([\n",
    "    ('UNK', [0, 0, 0, 0]),\n",
    "    ('A', [1, 0, 0, 0]),\n",
    "    ('C', [0, 1, 0, 0]),\n",
    "    ('G', [0, 0, 1, 0]),\n",
    "    ('T', [0, 0, 0, 1]),\n",
    "    ('N', [0.25, 0.25, 0.25, 0.25]),  # A or C or G or T\n",
    "])\n",
    "\n",
    "encoding_keys = list(encoding_seq.keys())\n",
    "seq_encoding_vectors = np.array(list(encoding_seq.values()))\n",
    "encoding_vectors = seq_encoding_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ERM', 'KDEL', 'LMA', 'MITO', 'NES', 'NIK', 'NLS', 'NUCP', 'OMM'])\n",
      "['ERM', 'KDEL', 'LMA', 'MITO', 'NES', 'NIK', 'NLS', 'NUCP', 'OMM']\n",
      "            ERM      KDEL       LMA      MITO       NES       NIK       NLS  \\\n",
      "0      0.207338  0.128871  0.079991  0.044906  0.082833  0.088109  0.061681   \n",
      "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2      0.064346  0.125935  0.108187  0.082002  0.091019  0.160823  0.142649   \n",
      "3      0.141112  0.094932  0.211394  0.028049  0.102672  0.102581  0.124625   \n",
      "4      0.172315  0.115240  0.132014  0.039526  0.115743  0.088187  0.142063   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "13805  0.000000  0.000000  0.734451  0.109981  0.073566  0.000000  0.082002   \n",
      "13806  0.067811  0.056029  0.110082  0.010354  0.050838  0.430809  0.110393   \n",
      "13807  0.006797  0.081510  0.077941  0.046627  0.059330  0.330415  0.263028   \n",
      "13808  0.000000  0.077421  0.315861  0.053726  0.132350  0.051426  0.189963   \n",
      "13809  0.000000  0.307638  0.000000  0.044530  0.214586  0.000000  0.410580   \n",
      "\n",
      "           NUCP       OMM  \n",
      "0      0.106670  0.199601  \n",
      "1      0.922605  0.077395  \n",
      "2      0.131566  0.093474  \n",
      "3      0.090767  0.103868  \n",
      "4      0.105034  0.089878  \n",
      "...         ...       ...  \n",
      "13805  0.000000  0.000000  \n",
      "13806  0.000000  0.163685  \n",
      "13807  0.045733  0.088620  \n",
      "13808  0.110591  0.068661  \n",
      "13809  0.000000  0.022666  \n",
      "\n",
      "[12429 rows x 9 columns]\n",
      "[[0.20733762 0.12887145 0.0799912  ... 0.06168086 0.10666985 0.19960129]\n",
      " [0.         0.         0.         ... 0.         0.92260468 0.07739532]\n",
      " [0.06434552 0.12593526 0.10818672 ... 0.14264876 0.1315659  0.0934739 ]\n",
      " ...\n",
      " [0.00679663 0.08151006 0.07794138 ... 0.26302778 0.04573318 0.08861974]\n",
      " [0.         0.07742136 0.31586081 ... 0.18996313 0.11059064 0.06866123]\n",
      " [0.         0.307638   0.         ... 0.41058008 0.         0.02266626]]\n"
     ]
    }
   ],
   "source": [
    "#print(mapping_localisations.keys())\n",
    "#print(list(mapping_localisations.keys()))\n",
    "#print(data_one_no_struct[mapping_localisations.keys()])\n",
    "#print(data_one_no_struct[mapping_localisations.keys()].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK', 'A', 'C', 'G', 'T', 'N']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = pad_sequences([[encoding_keys.index(c) for c in gene] for gene in gene_data],\n",
    "                    maxlen=max_len,\n",
    "                    dtype=np.int8, value=encoding_keys.index('UNK'))  # , truncating='post')\n",
    "\n",
    "y = data_one_no_struct[mapping_localisations.keys()].values\n",
    "\n",
    "# y = np.array([label_dist(gene.dist) for gene in gene_data])\n",
    "\n",
    "#template = [0] * 24  # TODO: why 24? # dim([a,c,g,t]) * dim([f,t,i,h,m,s])\n",
    "#combined_encoding = OrderedDict()\n",
    "#combined_encoding['UNK'] = template\n",
    "#for i, (key_seq, key_ann) in enumerate(\n",
    "#        itertools.product(['A', 'C', 'G', 'T', 'N'], ['F', 'T', 'I', 'H', 'M', 'S'])):\n",
    "#    tmp = template.copy()\n",
    "#    if key_seq == 'N':\n",
    "#        for n in ['A', 'C', 'G', 'T']:\n",
    "#            tmp[np.nonzero(combined_encoding[n + key_ann])[0][0]] = 0.25\n",
    "#        combined_encoding[key_seq + key_ann] = tmp\n",
    "#    else:\n",
    "#        tmp[i] = 1  # normal one-hot encoding as it is...\n",
    "#        combined_encoding[key_seq + key_ann] = tmp\n",
    "#encoding_keys = list(combined_encoding.keys())\n",
    "#encoding_vectors = np.array(list(combined_encoding.values()))\n",
    "#encoding_vectors\n",
    "##print(len(encoding_vectors))\n",
    "encoding_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: what is this?\n",
    "# check\n",
    "\n",
    "# Generating one-hot encoding sequences\n",
    " \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "encoding_seq = OrderedDict([\n",
    "    ('UNK', [0, 0, 0, 0]),\n",
    "    ('A', [1, 0, 0, 0]),\n",
    "    ('C', [0, 1, 0, 0]),\n",
    "    ('G', [0, 0, 1, 0]),\n",
    "    ('T', [0, 0, 0, 1]),\n",
    "    ('N', [0.25, 0.25, 0.25, 0.25]),  # A or C or G or T\n",
    "])\n",
    "\n",
    "template = [0] * 24  # TODO: why 24? # dim([a,c,g,t]) * dim([f,t,i,h,m,s])\n",
    "combined_encoding = OrderedDict()\n",
    "combined_encoding['UNK'] = template\n",
    "for i, (key_seq, key_ann) in enumerate(\n",
    "        itertools.product(['A', 'C', 'G', 'T', 'N'], ['F', 'T', 'I', 'H', 'M', 'S'])):\n",
    "    tmp = template.copy()\n",
    "    if key_seq == 'N':\n",
    "        for n in ['A', 'C', 'G', 'T']:\n",
    "            tmp[np.nonzero(combined_encoding[n + key_ann])[0][0]] = 0.25\n",
    "        combined_encoding[key_seq + key_ann] = tmp\n",
    "    else:\n",
    "        tmp[i] = 1  # normal one-hot encoding as it is...\n",
    "        combined_encoding[key_seq + key_ann] = tmp\n",
    "encoding_keys = list(combined_encoding.keys())\n",
    "encoding_vectors = np.array(list(combined_encoding.values()))\n",
    "encoding_vectors\n",
    "#print(len(encoding_vectors))\n",
    "\n",
    "\n",
    "# Loading in X and y\n",
    "\n",
    "seq_encoding_keys = list(encoding_seq.keys())\n",
    "seq_encoding_vectors = np.array(list(encoding_seq.values()))\n",
    "#annotation_encoding_keys = list(encoding_annotation.keys())\n",
    "#annotation_encoding_vectors = np.array(list(encoding_annotation.values()))\n",
    "\n",
    "# Loading in Gene Sequence in a Wrapper\n",
    "\n",
    "gene_data = Gene_Wrapper.seq_data_loader(False, dataset, lower_bound, upper_bound,\n",
    "                                            permute=randomization_test) # use_annotations, dataset, lower_bound, upper_bound, permute=randomization_test\n",
    "\n",
    "\n",
    "encoding_keys = seq_encoding_keys\n",
    "encoding_vectors = seq_encoding_vectors\n",
    "X = pad_sequences([[encoding_keys.index(c) for c in gene.seq] for gene in gene_data],\n",
    "                    maxlen=max_len,\n",
    "                    dtype=np.int8, value=encoding_keys.index('UNK'))  # , truncating='post')\n",
    "y = np.array([label_dist(gene.dist) for gene in gene_data])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting for 5fold\n",
    "\n",
    "folds_total = 5\n",
    "\n",
    "kf = KFold(n_splits=folds_total, shuffle=True, random_state=1234)\n",
    "folds = kf.split(X, y)\n",
    "\n",
    "# folds now contains a list of lists. Each sublist contains all the indices for the pandas data entries to be used in the respective fold\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2** |  Importing models...\n",
    "\n",
    "We use as baseline model the [RNATracker](https://github.com/HarveyYan/RNATracker/blob/master/Models/cnn_bilstm_attention.py) model and a CNN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '~/Downloads/model_outputs'\n"
     ]
    }
   ],
   "source": [
    "# Import NN\n",
    "from RNAtracker import RNATracker\n",
    "\n",
    "# TODO: do a normal CNN\n",
    "\n",
    "\n",
    "# Set paths for model output\n",
    "try:\n",
    "    os.makedirs('~/Downloads/model_outputs')\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "model_output_folder = '~/Downloads/model_outputs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KFolds 1/5\n",
      "Advanced Masking\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 4000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 4000, 4)      24          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 3991, 32)     1280        ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 1330, 32)    0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1330, 32)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 1321, 32)     10240       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 440, 32)     0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 440, 32)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " masking_1 (Masking)            (None, 440, 32)      0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 440, 64)     16640       ['masking_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 440, 64)      0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 440, 50)      3250        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 440, 1)       50          ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 440)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 440)          0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 440, 1)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 440, 64)      0           ['lambda_2[0][0]',               \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 64)           0           ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 9)            585         ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,069\n",
      "Trainable params: 32,045\n",
      "Non-trainable params: 24\n",
      "__________________________________________________________________________________________________\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.1731 - acc: 0.1632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m#model.build_model(nb_filters=kwargs['nb_filters'], filters_length=kwargs['filters_length'],\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m#                          pooling_size=kwargs['pooling_size'], lstm_units=kwargs['lstm_units'],\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m#                          embedding_vec=encoding_vectors)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mbuild_model_advanced_masking(nb_filters\u001b[39m=\u001b[39mnb_filters,\n\u001b[1;32m     13\u001b[0m                                                filters_length\u001b[39m=\u001b[39mfilters_length,\n\u001b[1;32m     14\u001b[0m                                                pooling_size\u001b[39m=\u001b[39mpooling_size,\n\u001b[1;32m     15\u001b[0m                                                lstm_units\u001b[39m=\u001b[39mlstm_units,\n\u001b[1;32m     16\u001b[0m                                                embedding_vec\u001b[39m=\u001b[39mencoding_vectors)\n\u001b[0;32m---> 19\u001b[0m model\u001b[39m.\u001b[39;49mtrain(X[train_indices], y[train_indices], batch_size,epochs)\n\u001b[1;32m     21\u001b[0m model\u001b[39m.\u001b[39mevaluate(X[test_indices], y[test_indices], dataset)\n\u001b[1;32m     23\u001b[0m K\u001b[39m.\u001b[39mclear_session()\n",
      "File \u001b[0;32m~/Documents/main_storage/STUDY RESOURCES/Regulatory Genomics/project/files2/rna-localization/RNAtracker.py:808\u001b[0m, in \u001b[0;36mRNATracker.train\u001b[0;34m(self, x_train, y_train, batch_size, epochs)\u001b[0m\n\u001b[1;32m    806\u001b[0m best_model_path \u001b[39m=\u001b[39m OUTPATH \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweights_fold_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkfold_index)\n\u001b[1;32m    807\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(best_model_path, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 808\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mevaluate(x_train, y_train, batch_size\u001b[39m=\u001b[39;49mbatch_size))\n\u001b[1;32m    809\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mevaluate(x_valid, y_valid, batch_size\u001b[39m=\u001b[39mbatch_size))\n\u001b[1;32m    810\u001b[0m hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39mbatch_size, epochs\u001b[39m=\u001b[39mepochs, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    811\u001b[0m                       validation_data\u001b[39m=\u001b[39m(x_valid, y_valid), callbacks\u001b[39m=\u001b[39m[model_checkpoint], shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/keras/engine/training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2069\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2070\u001b[0m ):\n\u001b[1;32m   2071\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2072\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   2073\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2074\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/reggen/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: with understand what we have to predict, we can allocate X and y\n",
    "# Also: the kwargsvalues are hyperparameters of which we will select default values from the RNAtracker repo\n",
    "epochs = 10\n",
    "\n",
    "for i, (train_indices, test_indices) in enumerate(folds):\n",
    "    print('Evaluating KFolds {}/{}'.format(str(i + 1), str(folds_total)))\n",
    "    model = RNATracker(max_len, nb_classes, model_output_folder, kfold_index=i)\n",
    "    #model.build_model(nb_filters=kwargs['nb_filters'], filters_length=kwargs['filters_length'],\n",
    "    #                          pooling_size=kwargs['pooling_size'], lstm_units=kwargs['lstm_units'],\n",
    "    #                          embedding_vec=encoding_vectors)\n",
    "    \n",
    "    model.build_model_advanced_masking(nb_filters=nb_filters,\n",
    "                                                   filters_length=filters_length,\n",
    "                                                   pooling_size=pooling_size,\n",
    "                                                   lstm_units=lstm_units,\n",
    "                                                   embedding_vec=encoding_vectors)\n",
    "    \n",
    "\n",
    "    model.train(X[train_indices], y[train_indices], batch_size,epochs)\n",
    "\n",
    "    model.evaluate(X[test_indices], y[test_indices], dataset)\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna_localization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
