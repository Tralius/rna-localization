{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Genomics Project **RNA Localisation**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Problem definition**:\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.** First steps with data\n",
    "\n",
    "Firstly, we import several necessary packages and load in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:36:06.594328500Z",
     "start_time": "2023-06-15T00:36:06.588805700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from keras.utils import to_categorical\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:36:11.866618600Z",
     "start_time": "2023-06-15T00:36:09.182705900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             ERM       KDEL        LMA       MITO        NES        NIK  \\\n0      57.045409  35.456782  22.008215  12.355106  22.789983  24.241731   \n1       0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n2      17.449430  34.151539  29.338431  22.237585  24.682767  43.612551   \n3       3.830180   2.576734   5.737850   0.761343   2.786808   2.784356   \n4      13.132915   8.782925  10.061390   3.012459   8.821250   6.721117   \n...          ...        ...        ...        ...        ...        ...   \n13805   0.000000   0.000000   0.506809   0.075893   0.050764   0.000000   \n13806   0.105452   0.087130   0.171187   0.016101   0.079057   0.669947   \n13807   0.037093   0.444844   0.425368   0.254467   0.323794   1.803249   \n13808   0.000000   0.519421   2.119115   0.360450   0.887939   0.345021   \n13809   0.000000   0.226187   0.000000   0.032740   0.157772   0.000000   \n\n             NLS       NUCP        OMM          gene_id    gene_biotype  \\\n0      16.970436  29.348389  54.916891  ENSG00000000003  protein_coding   \n1       0.000000   2.914814   0.244517  ENSG00000000005  protein_coding   \n2      38.683963  35.678476  25.348560  ENSG00000000419  protein_coding   \n3       3.382682   2.463676   2.819269  ENSG00000000457  protein_coding   \n4      10.827253   8.005113   6.849962  ENSG00000000460  protein_coding   \n...          ...        ...        ...              ...             ...   \n13805   0.056586   0.000000   0.000000  ENSG00000281883  protein_coding   \n13806   0.171672   0.000000   0.254546  ENSG00000282034  protein_coding   \n13807   1.435483   0.249590   0.483645  ENSG00000282827  protein_coding   \n13808   1.274465   0.741954   0.460649  ENSG00000282936  protein_coding   \n13809   0.301875   0.000000   0.016665  ENSG00000282988  protein_coding   \n\n                                                     seq  \\\n0      ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...   \n1      TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...   \n2      TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...   \n3      TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...   \n4      AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...   \n...                                                  ...   \n13805  GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...   \n13806  GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...   \n13807  ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...   \n13808  CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...   \n13809  TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...   \n\n                                                  struct  m6A_5UTR  m6A_CDS  \\\n0      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n1      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n2      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n3      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        9   \n4      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n...                                                  ...       ...      ...   \n13805  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        2   \n13806  [0.37599998712539673, 0.0, 0.07500000298023224...         0       66   \n13807  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n13808  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n13809  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...         0        0   \n\n       m6A_3UTR  \n0             1  \n1             0  \n2             0  \n3             5  \n4             2  \n...         ...  \n13805         1  \n13806         4  \n13807         0  \n13808         2  \n13809         0  \n\n[13810 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ERM</th>\n      <th>KDEL</th>\n      <th>LMA</th>\n      <th>MITO</th>\n      <th>NES</th>\n      <th>NIK</th>\n      <th>NLS</th>\n      <th>NUCP</th>\n      <th>OMM</th>\n      <th>gene_id</th>\n      <th>gene_biotype</th>\n      <th>seq</th>\n      <th>struct</th>\n      <th>m6A_5UTR</th>\n      <th>m6A_CDS</th>\n      <th>m6A_3UTR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57.045409</td>\n      <td>35.456782</td>\n      <td>22.008215</td>\n      <td>12.355106</td>\n      <td>22.789983</td>\n      <td>24.241731</td>\n      <td>16.970436</td>\n      <td>29.348389</td>\n      <td>54.916891</td>\n      <td>ENSG00000000003</td>\n      <td>protein_coding</td>\n      <td>ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.914814</td>\n      <td>0.244517</td>\n      <td>ENSG00000000005</td>\n      <td>protein_coding</td>\n      <td>TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.449430</td>\n      <td>34.151539</td>\n      <td>29.338431</td>\n      <td>22.237585</td>\n      <td>24.682767</td>\n      <td>43.612551</td>\n      <td>38.683963</td>\n      <td>35.678476</td>\n      <td>25.348560</td>\n      <td>ENSG00000000419</td>\n      <td>protein_coding</td>\n      <td>TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.830180</td>\n      <td>2.576734</td>\n      <td>5.737850</td>\n      <td>0.761343</td>\n      <td>2.786808</td>\n      <td>2.784356</td>\n      <td>3.382682</td>\n      <td>2.463676</td>\n      <td>2.819269</td>\n      <td>ENSG00000000457</td>\n      <td>protein_coding</td>\n      <td>TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.132915</td>\n      <td>8.782925</td>\n      <td>10.061390</td>\n      <td>3.012459</td>\n      <td>8.821250</td>\n      <td>6.721117</td>\n      <td>10.827253</td>\n      <td>8.005113</td>\n      <td>6.849962</td>\n      <td>ENSG00000000460</td>\n      <td>protein_coding</td>\n      <td>AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13805</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.506809</td>\n      <td>0.075893</td>\n      <td>0.050764</td>\n      <td>0.000000</td>\n      <td>0.056586</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>ENSG00000281883</td>\n      <td>protein_coding</td>\n      <td>GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13806</th>\n      <td>0.105452</td>\n      <td>0.087130</td>\n      <td>0.171187</td>\n      <td>0.016101</td>\n      <td>0.079057</td>\n      <td>0.669947</td>\n      <td>0.171672</td>\n      <td>0.000000</td>\n      <td>0.254546</td>\n      <td>ENSG00000282034</td>\n      <td>protein_coding</td>\n      <td>GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...</td>\n      <td>[0.37599998712539673, 0.0, 0.07500000298023224...</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13807</th>\n      <td>0.037093</td>\n      <td>0.444844</td>\n      <td>0.425368</td>\n      <td>0.254467</td>\n      <td>0.323794</td>\n      <td>1.803249</td>\n      <td>1.435483</td>\n      <td>0.249590</td>\n      <td>0.483645</td>\n      <td>ENSG00000282827</td>\n      <td>protein_coding</td>\n      <td>ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13808</th>\n      <td>0.000000</td>\n      <td>0.519421</td>\n      <td>2.119115</td>\n      <td>0.360450</td>\n      <td>0.887939</td>\n      <td>0.345021</td>\n      <td>1.274465</td>\n      <td>0.741954</td>\n      <td>0.460649</td>\n      <td>ENSG00000282936</td>\n      <td>protein_coding</td>\n      <td>CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>0.000000</td>\n      <td>0.226187</td>\n      <td>0.000000</td>\n      <td>0.032740</td>\n      <td>0.157772</td>\n      <td>0.000000</td>\n      <td>0.301875</td>\n      <td>0.000000</td>\n      <td>0.016665</td>\n      <td>ENSG00000282988</td>\n      <td>protein_coding</td>\n      <td>TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13810 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing test set\n",
    "np.random.seed(3)\n",
    "data_org = pd.read_csv('final_data.csv')\n",
    "test_data = data_org.sample(frac=0.1)\n",
    "train_data = data_org.drop(test_data.index)\n",
    "\n",
    "data_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:36:13.335206200Z",
     "start_time": "2023-06-15T00:36:13.323021400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            ERM      KDEL       LMA      MITO       NES       NIK       NLS  \\\n0      0.207338  0.128871  0.079991  0.044906  0.082833  0.088109  0.061681   \n1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n2      0.064346  0.125935  0.108187  0.082002  0.091019  0.160823  0.142649   \n3      0.141112  0.094932  0.211394  0.028049  0.102672  0.102581  0.124625   \n4      0.172315  0.115240  0.132014  0.039526  0.115743  0.088187  0.142063   \n...         ...       ...       ...       ...       ...       ...       ...   \n13805  0.000000  0.000000  0.734451  0.109981  0.073566  0.000000  0.082002   \n13806  0.067811  0.056029  0.110082  0.010354  0.050838  0.430809  0.110393   \n13807  0.006797  0.081510  0.077941  0.046627  0.059330  0.330415  0.263028   \n13808  0.000000  0.077421  0.315861  0.053726  0.132350  0.051426  0.189963   \n13809  0.000000  0.307638  0.000000  0.044530  0.214586  0.000000  0.410580   \n\n           NUCP       OMM                                                seq  \n0      0.106670  0.199601  ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...  \n1      0.922605  0.077395  TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...  \n2      0.131566  0.093474  TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...  \n3      0.090767  0.103868  TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...  \n4      0.105034  0.089878  AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...  \n...         ...       ...                                                ...  \n13805  0.000000  0.000000  GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...  \n13806  0.000000  0.163685  GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...  \n13807  0.045733  0.088620  ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...  \n13808  0.110591  0.068661  CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...  \n13809  0.000000  0.022666  TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...  \n\n[13810 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ERM</th>\n      <th>KDEL</th>\n      <th>LMA</th>\n      <th>MITO</th>\n      <th>NES</th>\n      <th>NIK</th>\n      <th>NLS</th>\n      <th>NUCP</th>\n      <th>OMM</th>\n      <th>seq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.207338</td>\n      <td>0.128871</td>\n      <td>0.079991</td>\n      <td>0.044906</td>\n      <td>0.082833</td>\n      <td>0.088109</td>\n      <td>0.061681</td>\n      <td>0.106670</td>\n      <td>0.199601</td>\n      <td>ACCTTGTATTAGGTATTTATTTCCACAAAAGTTTGATGCTTACAAC...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.922605</td>\n      <td>0.077395</td>\n      <td>TGTGCACAGAAGTTATATACATATATGGGTATATCTATGTAACAAA...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.064346</td>\n      <td>0.125935</td>\n      <td>0.108187</td>\n      <td>0.082002</td>\n      <td>0.091019</td>\n      <td>0.160823</td>\n      <td>0.142649</td>\n      <td>0.131566</td>\n      <td>0.093474</td>\n      <td>TACTTTATGCAAAAAAAAATATACATTTATTTATAGGTCTCAATAC...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.141112</td>\n      <td>0.094932</td>\n      <td>0.211394</td>\n      <td>0.028049</td>\n      <td>0.102672</td>\n      <td>0.102581</td>\n      <td>0.124625</td>\n      <td>0.090767</td>\n      <td>0.103868</td>\n      <td>TGACTTTCAAACCATTTTAATATTTCAAATATTCCAGAACAATCCC...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.172315</td>\n      <td>0.115240</td>\n      <td>0.132014</td>\n      <td>0.039526</td>\n      <td>0.115743</td>\n      <td>0.088187</td>\n      <td>0.142063</td>\n      <td>0.105034</td>\n      <td>0.089878</td>\n      <td>AACCCGCTCGGGTCCCCTTCCACACTGTGGAAGCTTTGTTCTTTCG...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13805</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.734451</td>\n      <td>0.109981</td>\n      <td>0.073566</td>\n      <td>0.000000</td>\n      <td>0.082002</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>GGGAAGAAAGGAGCCTGACTCTTATGATGGAATAACCACAAATCAG...</td>\n    </tr>\n    <tr>\n      <th>13806</th>\n      <td>0.067811</td>\n      <td>0.056029</td>\n      <td>0.110082</td>\n      <td>0.010354</td>\n      <td>0.050838</td>\n      <td>0.430809</td>\n      <td>0.110393</td>\n      <td>0.000000</td>\n      <td>0.163685</td>\n      <td>GTGTCGGACGGCATGACAGGCAGCAATCCTGTGTCCCCTGCCTCAT...</td>\n    </tr>\n    <tr>\n      <th>13807</th>\n      <td>0.006797</td>\n      <td>0.081510</td>\n      <td>0.077941</td>\n      <td>0.046627</td>\n      <td>0.059330</td>\n      <td>0.330415</td>\n      <td>0.263028</td>\n      <td>0.045733</td>\n      <td>0.088620</td>\n      <td>ATGGCGGGGACCTCCGCGCCAGGCAGCAAGAGGCGGAGCGAGCCCC...</td>\n    </tr>\n    <tr>\n      <th>13808</th>\n      <td>0.000000</td>\n      <td>0.077421</td>\n      <td>0.315861</td>\n      <td>0.053726</td>\n      <td>0.132350</td>\n      <td>0.051426</td>\n      <td>0.189963</td>\n      <td>0.110591</td>\n      <td>0.068661</td>\n      <td>CTACTGGAACGCCCCCCTCAATCTAGCCTCCCCCACATAACTCTCT...</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>0.000000</td>\n      <td>0.307638</td>\n      <td>0.000000</td>\n      <td>0.044530</td>\n      <td>0.214586</td>\n      <td>0.000000</td>\n      <td>0.410580</td>\n      <td>0.000000</td>\n      <td>0.022666</td>\n      <td>TGGTCTATCTCCCAAGTCAAAGACTGAAGTAAAGAAAAAGGTTGCA...</td>\n    </tr>\n  </tbody>\n</table>\n<p>13810 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vec = data_org.iloc[:, :9].sum(axis=1)\n",
    "data2 = data_org.iloc[:, :9].divide(sum_vec, axis='index')\n",
    "data = pd.concat([data2, data_org['seq']], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:36:18.818517100Z",
     "start_time": "2023-06-15T00:36:15.024242200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            ERM      KDEL       LMA      MITO       NES       NIK       NLS  \\\n0      0.207338  0.128871  0.079991  0.044906  0.082833  0.088109  0.061681   \n1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n2      0.064346  0.125935  0.108187  0.082002  0.091019  0.160823  0.142649   \n3      0.141112  0.094932  0.211394  0.028049  0.102672  0.102581  0.124625   \n4      0.172315  0.115240  0.132014  0.039526  0.115743  0.088187  0.142063   \n...         ...       ...       ...       ...       ...       ...       ...   \n13805  0.000000  0.000000  0.734451  0.109981  0.073566  0.000000  0.082002   \n13806  0.067811  0.056029  0.110082  0.010354  0.050838  0.430809  0.110393   \n13807  0.006797  0.081510  0.077941  0.046627  0.059330  0.330415  0.263028   \n13808  0.000000  0.077421  0.315861  0.053726  0.132350  0.051426  0.189963   \n13809  0.000000  0.307638  0.000000  0.044530  0.214586  0.000000  0.410580   \n\n           NUCP       OMM                                                seq  \n0      0.106670  0.199601  [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...  \n1      0.922605  0.077395  [[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0], [...  \n2      0.131566  0.093474  [[0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0], [...  \n3      0.090767  0.103868  [[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0], [...  \n4      0.105034  0.089878  [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [...  \n...         ...       ...                                                ...  \n13805  0.000000  0.000000  [[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0], [...  \n13806  0.000000  0.163685  [[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...  \n13807  0.045733  0.088620  [[1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...  \n13808  0.110591  0.068661  [[0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...  \n13809  0.000000  0.022666  [[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0], [...  \n\n[13810 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ERM</th>\n      <th>KDEL</th>\n      <th>LMA</th>\n      <th>MITO</th>\n      <th>NES</th>\n      <th>NIK</th>\n      <th>NLS</th>\n      <th>NUCP</th>\n      <th>OMM</th>\n      <th>seq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.207338</td>\n      <td>0.128871</td>\n      <td>0.079991</td>\n      <td>0.044906</td>\n      <td>0.082833</td>\n      <td>0.088109</td>\n      <td>0.061681</td>\n      <td>0.106670</td>\n      <td>0.199601</td>\n      <td>[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.922605</td>\n      <td>0.077395</td>\n      <td>[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0], [...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.064346</td>\n      <td>0.125935</td>\n      <td>0.108187</td>\n      <td>0.082002</td>\n      <td>0.091019</td>\n      <td>0.160823</td>\n      <td>0.142649</td>\n      <td>0.131566</td>\n      <td>0.093474</td>\n      <td>[[0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0], [...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.141112</td>\n      <td>0.094932</td>\n      <td>0.211394</td>\n      <td>0.028049</td>\n      <td>0.102672</td>\n      <td>0.102581</td>\n      <td>0.124625</td>\n      <td>0.090767</td>\n      <td>0.103868</td>\n      <td>[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0], [...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.172315</td>\n      <td>0.115240</td>\n      <td>0.132014</td>\n      <td>0.039526</td>\n      <td>0.115743</td>\n      <td>0.088187</td>\n      <td>0.142063</td>\n      <td>0.105034</td>\n      <td>0.089878</td>\n      <td>[[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13805</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.734451</td>\n      <td>0.109981</td>\n      <td>0.073566</td>\n      <td>0.000000</td>\n      <td>0.082002</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>[[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0], [...</td>\n    </tr>\n    <tr>\n      <th>13806</th>\n      <td>0.067811</td>\n      <td>0.056029</td>\n      <td>0.110082</td>\n      <td>0.010354</td>\n      <td>0.050838</td>\n      <td>0.430809</td>\n      <td>0.110393</td>\n      <td>0.000000</td>\n      <td>0.163685</td>\n      <td>[[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n    </tr>\n    <tr>\n      <th>13807</th>\n      <td>0.006797</td>\n      <td>0.081510</td>\n      <td>0.077941</td>\n      <td>0.046627</td>\n      <td>0.059330</td>\n      <td>0.330415</td>\n      <td>0.263028</td>\n      <td>0.045733</td>\n      <td>0.088620</td>\n      <td>[[1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n    </tr>\n    <tr>\n      <th>13808</th>\n      <td>0.000000</td>\n      <td>0.077421</td>\n      <td>0.315861</td>\n      <td>0.053726</td>\n      <td>0.132350</td>\n      <td>0.051426</td>\n      <td>0.189963</td>\n      <td>0.110591</td>\n      <td>0.068661</td>\n      <td>[[0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>0.000000</td>\n      <td>0.307638</td>\n      <td>0.000000</td>\n      <td>0.044530</td>\n      <td>0.214586</td>\n      <td>0.000000</td>\n      <td>0.410580</td>\n      <td>0.000000</td>\n      <td>0.022666</td>\n      <td>[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0], [...</td>\n    </tr>\n  </tbody>\n</table>\n<p>13810 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode the 'seq' attribute of the above table\n",
    "mapping = { \n",
    "            'A': 0,\n",
    "            'C': 1,\n",
    "            'G': 2,\n",
    "            'T': 3\n",
    "            }\n",
    "one_hot_encode_lam = lambda seq: to_categorical([mapping[x] for x in seq])\n",
    "data_one_hot_karas = data['seq'].apply(one_hot_encode_lam)\n",
    "\n",
    "data_one_hot_karas\n",
    "\n",
    "# Now just injecting this modified 'seq' back into the pandas frame \n",
    "data_new_karas =  pd.concat([data.iloc[:, :9], data_one_hot_karas], axis=1)\n",
    "\n",
    "data_new_karas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:53:33.569452200Z",
     "start_time": "2023-06-15T00:53:30.956879300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "(13810, 4, 2000)\n",
      "(13810, 9)\n"
     ]
    }
   ],
   "source": [
    "# Splitting for 5fold\n",
    "\n",
    "folds_total = 5\n",
    "\n",
    "lengths = data_new_karas['seq'].apply(lambda x: len(x))\n",
    "\n",
    "# max_length = lengths.max()\n",
    "\n",
    "max_length = 2000\n",
    "\n",
    "print(max_length)\n",
    "\n",
    "def pad(x):\n",
    "    if len(x) < max_length:\n",
    "        return np.concatenate((x, np.array([np.array([0.0, 0.0, 0.0, 0.0]) for i in range(max_length - len(x))])), axis=0)\n",
    "    else:\n",
    "        return x[:max_length]\n",
    "\n",
    "X = data_new_karas['seq'].apply(pad)\n",
    "# X = data_new_karas['seq']\n",
    "\n",
    "# y = pd.DataFrame(columns=['Labels'])\n",
    "\n",
    "# X = tf.data.Dataset.from_tensor_slices(dict(X))\n",
    "\n",
    "y = data_new_karas.iloc[:, :9].values.tolist()\n",
    "# y = y.apply(lambda x: np.array(x))\n",
    "\n",
    "# y = tf.data.Dataset.from_tensor_slices(dict(y))\n",
    "\n",
    "X = np.stack(X).transpose((0, 2, 1))\n",
    "y = np.stack(y)\n",
    "\n",
    "# X = tf.convert_to_tensor(X)\n",
    "# y = tf.convert_to_tensor(y)\n",
    "\n",
    "# kf = KFold(n_splits=folds_total, shuffle=True, random_state=1234)\n",
    "\n",
    "# folds = kf.split(X, y)\n",
    "\n",
    "kf = KFold(n_splits=folds_total, shuffle=True, random_state=1)\n",
    "\n",
    "folds = kf.split(X,y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# folds now contains a list of lists. Each sublist contains all the indices for the pandas data entries to be used in the respective fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is this?\n",
    "\n",
    "template = [0] * 24  # dim([a,c,g,t]) * dim([f,t,i,h,m,s])\n",
    "combined_encoding = OrderedDict()\n",
    "combined_encoding['UNK'] = template\n",
    "for i, (key_seq, key_ann) in enumerate(\n",
    "        itertools.product(['A', 'C', 'G', 'T', 'N'], ['F', 'T', 'I', 'H', 'M', 'S'])):\n",
    "    tmp = template.copy()\n",
    "    if key_seq == 'N':\n",
    "        for n in ['A', 'C', 'G', 'T']:\n",
    "            tmp[np.nonzero(combined_encoding[n + key_ann])[0][0]] = 0.25\n",
    "        combined_encoding[key_seq + key_ann] = tmp\n",
    "    else:\n",
    "        tmp[i] = 1  # normal one-hot encoding as it is...\n",
    "        combined_encoding[key_seq + key_ann] = tmp\n",
    "encoding_keys = list(combined_encoding.keys())\n",
    "encoding_vectors = np.array(list(combined_encoding.values()))\n",
    "encoding_vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2** |  Importing models...\n",
    "\n",
    "We use as baseline model the [RNATracker](https://github.com/HarveyYan/RNATracker/blob/master/Models/cnn_bilstm_attention.py) model and a CNN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:53:35.340767200Z",
     "start_time": "2023-06-15T00:53:35.290674500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder already exists\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2, 32)             192032    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 2, 32)            0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 9)              297       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192,329\n",
      "Trainable params: 192,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import NN\n",
    "# from RNAtracker import RNATracker\n",
    "from cnn_model import CNN_MLRG\n",
    "\n",
    "# TODO: do a normal CNN\n",
    "import keras\n",
    "from keras.layers import Conv1D, Dense, Flatten, Input, MaxPooling1D, SpatialDropout1D\n",
    "\n",
    "# Set paths for model output\n",
    "try:\n",
    "    os.mkdir('model_outputs/')\n",
    "except Exception as e:\n",
    "    print(\"Output folder already exists\")\n",
    "\n",
    "model_output_folder = 'model_outputs/'\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(4, 2000)))\n",
    "# model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "# model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(SpatialDropout1D(rate=0.2))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dense(9, activation=\"softmax\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T00:53:53.120258800Z",
     "start_time": "2023-06-15T00:53:38.507528200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Evaluating KFolds 1/5\n",
      "Epoch 1/3\n",
      "335/346 [============================>.] - ETA: 0s - loss: 2.1832 - accuracy: 0.1542\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15206, saving model to model_outputs\\cnn0.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1830 - accuracy: 0.1536 - val_loss: 2.1745 - val_accuracy: 0.1521\n",
      "Epoch 2/3\n",
      "333/346 [===========================>..] - ETA: 0s - loss: 2.1734 - accuracy: 0.1546\n",
      "Epoch 2: val_accuracy did not improve from 0.15206\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1733 - accuracy: 0.1552 - val_loss: 2.1715 - val_accuracy: 0.1517\n",
      "Epoch 3/3\n",
      "333/346 [===========================>..] - ETA: 0s - loss: 2.1706 - accuracy: 0.1537\n",
      "Epoch 3: val_accuracy improved from 0.15206 to 0.15243, saving model to model_outputs\\cnn0.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1706 - accuracy: 0.1550 - val_loss: 2.1704 - val_accuracy: 0.1524\n",
      "87/87 [==============================] - 0s 477us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Evaluating KFolds 2/5\n",
      "Epoch 1/3\n",
      "328/346 [===========================>..] - ETA: 0s - loss: 2.1692 - accuracy: 0.1568\n",
      "Epoch 1: val_accuracy improved from -inf to 0.14772, saving model to model_outputs\\cnn1.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1694 - accuracy: 0.1574 - val_loss: 2.1661 - val_accuracy: 0.1477\n",
      "Epoch 2/3\n",
      "338/346 [============================>.] - ETA: 0s - loss: 2.1679 - accuracy: 0.1603\n",
      "Epoch 2: val_accuracy did not improve from 0.14772\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1679 - accuracy: 0.1605 - val_loss: 2.1669 - val_accuracy: 0.1434\n",
      "Epoch 3/3\n",
      "332/346 [===========================>..] - ETA: 0s - loss: 2.1666 - accuracy: 0.1636\n",
      "Epoch 3: val_accuracy did not improve from 0.14772\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1665 - accuracy: 0.1636 - val_loss: 2.1680 - val_accuracy: 0.1459\n",
      "87/87 [==============================] - 0s 488us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Evaluating KFolds 3/5\n",
      "Epoch 1/3\n",
      "337/346 [============================>.] - ETA: 0s - loss: 2.1683 - accuracy: 0.1610\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16980, saving model to model_outputs\\cnn2.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1683 - accuracy: 0.1610 - val_loss: 2.1642 - val_accuracy: 0.1698\n",
      "Epoch 2/3\n",
      "328/346 [===========================>..] - ETA: 0s - loss: 2.1671 - accuracy: 0.1638\n",
      "Epoch 2: val_accuracy did not improve from 0.16980\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1669 - accuracy: 0.1645 - val_loss: 2.1658 - val_accuracy: 0.1629\n",
      "Epoch 3/3\n",
      "336/346 [============================>.] - ETA: 0s - loss: 2.1660 - accuracy: 0.1663\n",
      "Epoch 3: val_accuracy did not improve from 0.16980\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1658 - accuracy: 0.1666 - val_loss: 2.1667 - val_accuracy: 0.1542\n",
      "87/87 [==============================] - 0s 477us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Evaluating KFolds 4/5\n",
      "Epoch 1/3\n",
      "321/346 [==========================>...] - ETA: 0s - loss: 2.1671 - accuracy: 0.1669\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17161, saving model to model_outputs\\cnn3.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1672 - accuracy: 0.1664 - val_loss: 2.1645 - val_accuracy: 0.1716\n",
      "Epoch 2/3\n",
      "339/346 [============================>.] - ETA: 0s - loss: 2.1657 - accuracy: 0.1668\n",
      "Epoch 2: val_accuracy improved from 0.17161 to 0.17234, saving model to model_outputs\\cnn3.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1657 - accuracy: 0.1675 - val_loss: 2.1681 - val_accuracy: 0.1723\n",
      "Epoch 3/3\n",
      "325/346 [===========================>..] - ETA: 0s - loss: 2.1649 - accuracy: 0.1697\n",
      "Epoch 3: val_accuracy did not improve from 0.17234\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1649 - accuracy: 0.1693 - val_loss: 2.1667 - val_accuracy: 0.1647\n",
      "87/87 [==============================] - 0s 471us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Evaluating KFolds 5/5\n",
      "Epoch 1/3\n",
      "345/346 [============================>.] - ETA: 0s - loss: 2.1658 - accuracy: 0.1674\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16329, saving model to model_outputs\\cnn4.h5\n",
      "346/346 [==============================] - 1s 3ms/step - loss: 2.1658 - accuracy: 0.1674 - val_loss: 2.1648 - val_accuracy: 0.1633\n",
      "Epoch 2/3\n",
      "332/346 [===========================>..] - ETA: 0s - loss: 2.1646 - accuracy: 0.1765\n",
      "Epoch 2: val_accuracy improved from 0.16329 to 0.16474, saving model to model_outputs\\cnn4.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1646 - accuracy: 0.1763 - val_loss: 2.1648 - val_accuracy: 0.1647\n",
      "Epoch 3/3\n",
      "335/346 [============================>.] - ETA: 0s - loss: 2.1641 - accuracy: 0.1764\n",
      "Epoch 3: val_accuracy improved from 0.16474 to 0.16582, saving model to model_outputs\\cnn4.h5\n",
      "346/346 [==============================] - 1s 2ms/step - loss: 2.1641 - accuracy: 0.1763 - val_loss: 2.1663 - val_accuracy: 0.1658\n",
      "87/87 [==============================] - 0s 483us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: with understand what we have to predict, we can allocate X and y\n",
    "# Also: the kwargsvalues are hyperparameters of which we will select default values from the RNAtracker repo\n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "\n",
    "for i, (train_indices, test_indices) in enumerate(folds):\n",
    "    print('Evaluating KFolds {}/{}'.format(str(i + 1), str(folds_total)))\n",
    "    # model = RNATracker(max_len, nb_classes, model_output_folder, kfold_index=i)\n",
    "    #model.build_model(nb_filters=kwargs['nb_filters'], filters_length=kwargs['filters_length'],\n",
    "    #                          pooling_size=kwargs['pooling_size'], lstm_units=kwargs['lstm_units'],\n",
    "    #                          embedding_vec=encoding_vectors)\n",
    "\n",
    "    # model.build_model_advanced_masking(nb_filters=kwargs['nb_filters'],\n",
    "     #                                              filters_length=kwargs['filters_length'],\n",
    "      #                                             pooling_size=kwargs['pooling_size'],\n",
    "       #                                            lstm_units=kwargs['lstm_units'],\n",
    "        #                                           embedding_vec=encoding_vectors)\n",
    "    \n",
    "\n",
    "    # model.train(X[train_indices], y[train_indices], batch_size, kwargs['epochs'])\n",
    "\n",
    "    # model.evaluate(X[test_indices], y[test_indices], dataset)\n",
    "\n",
    "    # K.clear_session()\n",
    "    model = model\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_output_folder + f\"cnn{i}.h5\",\n",
    "\t\t\t\t\t\t\tmonitor='val_accuracy', verbose=1,\n",
    "\t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    history = model.fit(X[train_indices], y[train_indices], epochs=3,\n",
    "                        callbacks=callbacks_list, validation_data=(X[test_indices], y[test_indices]))\n",
    "\n",
    "    model.load_weights(f\"model_outputs/cnn{i}.h5\")\n",
    "\n",
    "    results = model.evaluate(X[test_indices])\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Training done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna_localization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
