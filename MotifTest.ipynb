{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 13:33:29.636242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Modisco\n",
    "%matplotlib inline\n",
    "\n",
    "import modisco\n",
    "import json\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from metrics import Pearson\n",
    "from collections import OrderedDict, Counter, defaultdict\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from utils import prepare_data\n",
    "from deeplift.visualization import viz_sequence\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T11:33:36.682323Z",
     "start_time": "2023-07-16T11:33:13.294690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def one_hot_emb(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    mapping = {\n",
    "        'A': 0,\n",
    "        'C': 1,\n",
    "        'G': 2,\n",
    "        'T': 3\n",
    "    }\n",
    "    one_hot_encode_lam = lambda seq: to_categorical([mapping[x] for x in seq])\n",
    "    return data.apply(one_hot_encode_lam)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T11:34:26.311582Z",
     "start_time": "2023-07-16T11:34:26.287494Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = prepare_data()\n",
    "\n",
    "max_seq_len = train_data['seq'].apply(lambda x: len(x)).max()\n",
    "\n",
    "max_seq_len = 20788\n",
    "\n",
    "train_data['length'] = train_data.seq.str.len()\n",
    "\n",
    "train_data = train_data[train_data.length <= max_seq_len]\n",
    "\n",
    "data_one_hot = one_hot_emb(train_data['seq'])\n",
    "#data_struct = train_data['struct']\n",
    "\n",
    "#padded_sequences = np.zeros((len(train_data['seq']), max_seq_len, 6), dtype=np.float32)\n",
    "padded_sequences = np.zeros((len(train_data['seq']), max_seq_len, 4), dtype=np.float32)\n",
    "\n",
    "indices = np.arange(train_data.shape[0])\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    #tmp = data_struct.iloc[idx]\n",
    "    #padded_mask_struct = np.expand_dims(np.array(tmp != 'nan'), axis=1)\n",
    "    #tmp[tmp == 'nan'] = -1\n",
    "    #padded_struct = np.expand_dims(tmp, axis=1).astype('float64')\n",
    "    seq_data = data_one_hot.iloc[idx]\n",
    "    #seq_data = np.concatenate([seq_data, padded_mask_struct, padded_struct], axis=1)\n",
    "    padded_sequences[i, -len(data_one_hot.iloc[idx]):, :] = seq_data\n",
    "\n",
    "data_one_hot = padded_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T11:41:34.286660Z",
     "start_time": "2023-07-16T11:41:03.324167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 13:41:55.708201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-16 13:41:55.710241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-16 13:41:55.713270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Integrated Gradients\n",
    "\"\"\"\n",
    "from motif_search import motif_utilities\n",
    "\n",
    "\n",
    "model_name = \"moitfTest3\"\n",
    "\n",
    "model = load_model(f'model_outputs/{model_name}.keras',compile=False)\n",
    "\n",
    "seqs_to_explain = data_one_hot\n",
    "\n",
    "gradients = motif_utilities.get_gradients(model, seqs_to_explain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-16T11:41:53.448925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(gradients)\n",
    "# print(data_one_hot)\n",
    "\n",
    "viz_sequence.plot_weights(data_one_hot[0][:20], subticks_frequency=20)\n",
    "\n",
    "# motif_utilities.plot_weights(data_one_hot[0][:20])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Uncomment to refresh modules for when tweaking code during development:\n",
    "from importlib import reload\n",
    "reload(modisco.util)\n",
    "reload(modisco.pattern_filterer)\n",
    "reload(modisco.aggregator)\n",
    "reload(modisco.core)\n",
    "reload(modisco.seqlet_embedding.advanced_gapped_kmer)\n",
    "reload(modisco.affinitymat.transformers)\n",
    "reload(modisco.affinitymat.core)\n",
    "reload(modisco.affinitymat)\n",
    "reload(modisco.cluster.core)\n",
    "reload(modisco.cluster)\n",
    "reload(modisco.tfmodisco_workflow.seqlets_to_patterns)\n",
    "reload(modisco.tfmodisco_workflow)\n",
    "reload(modisco)\n",
    "\n",
    "scores = gradients\n",
    "hypothetical_scores = [] # optional\n",
    "\n",
    "tasks = {\n",
    "    \"task0\": \"Identify high-importance windows of the sequences, termed seqlets\",\n",
    "    \"task1\": \"Cluster recurring similar seqlets into motifs\",\n",
    "    \"task2\": \"Scan through importance scores across the genome to call motif instances (AKA hit scoring)\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "null_per_pos_scores = modisco.coordproducers.LaplaceNullDist(num_to_samp=5000)\n",
    "tfmodisco_results = modisco.tfmodisco_workflow.workflow.TfModiscoWorkflow(\n",
    "                    #Slight modifications from the default settings\n",
    "                    sliding_window_size=15,\n",
    "                    flank_size=5,\n",
    "                    target_seqlet_fdr=0.15,\n",
    "                    seqlets_to_patterns_factory=\n",
    "                     modisco.tfmodisco_workflow.seqlets_to_patterns.TfModiscoSeqletsToPatternsFactory(\n",
    "                        #Note: as of version 0.5.6.0, it's possible to use the results of a motif discovery\n",
    "                        # software like MEME to improve the TF-MoDISco clustering. To use the meme-based\n",
    "                        # initialization, you would specify the initclusterer_factory as shown in the\n",
    "                        # commented-out code below:\n",
    "                        #initclusterer_factory=modisco.clusterinit.memeinit.MemeInitClustererFactory(\n",
    "                        #    meme_command=\"meme\", base_outdir=\"meme_out\",\n",
    "                        #    max_num_seqlets_to_use=10000, nmotifs=10, n_jobs=1),\n",
    "                        trim_to_window_size=15,\n",
    "                        initial_flank_to_add=5,\n",
    "                        final_flank_to_add=5,\n",
    "                        final_min_cluster_size=60,\n",
    "                        #use_pynnd=True can be used for faster nn comp at coarse grained step\n",
    "                        # (it will use pynndescent), but note that pynndescent may crash\n",
    "                        #use_pynnd=True,\n",
    "                        n_cores=10)\n",
    "                )(\n",
    "                 task_names=[\"task0\"],#, \"task1\", \"task2\"],\n",
    "                 contrib_scores=scores,\n",
    "                 one_hot=data_one_hot,\n",
    "                 null_per_pos_scores=null_per_pos_scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPQdX4cOoZzqVG2F9xuy/Y",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
